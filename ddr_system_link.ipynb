{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limits of Scaling Memory Capacity\n",
    "\n",
    "# Introduction\n",
    "\n",
    "DDR memory DIMMs are a critical component of modern computer systems, providing the necessary memory capacity and bandwidth to support increasingly complex workloads. However, as memory capacity requirements continue to grow, it becomes increasingly important to understand the tradeoffs involved in different DDR memory DIMM architectures, such as UDIMM and LRDIMM, as well as the constraints imposed by DRAM and processor design and packaging. \n",
    "\n",
    "In this document, we will explore these tradeoffs and constraints, with the ultimate goal of answering the question: <span style=\"color:orange\">What the limiting factor is for scaling memory capacity?</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DDR systems vs LPDDR, GDDR, and HBM:**\n",
    "\n",
    "DDR (Double Data Rate) memory is a type of synchronous dynamic random-access memory (SDRAM) that is widely used in modern computer systems. It is designed to provide high-speed access to large amounts of data, making it ideal for use in applications such as gaming, video editing, and scientific computing.\n",
    "\n",
    "LPDDR (Low Power Double Data Rate) memory is a type of DDR memory that is optimized for use in mobile devices such as smartphones and tablets. It is designed to provide high-speed access to data while minimizing power consumption, making it ideal for use in battery-powered devices.\n",
    "\n",
    "GDDR (Graphics Double Data Rate) memory is a type of DDR memory that is optimized for use in graphics processing units (GPUs). It is designed to provide high-speed access to data while minimizing latency, making it ideal for use in applications such as gaming and video rendering.\n",
    "\n",
    "HBM (High Bandwidth Memory) is a type of memory that is designed to provide high-speed access to data while minimizing power consumption and physical footprint. It is commonly used in high-performance computing applications such as artificial intelligence and machine learning.\n",
    "\n",
    "While DDR, LPDDR, GDDR, and HBM all share some similarities in terms of their basic architecture, they are optimized for different use cases and have different performance characteristics. In this document, we will focus specifically on DDR memory and explore the tradeoffs involved in different DDR memory DIMM architectures, such as UDIMM and LRDIMM, as well as the constraints imposed by DRAM and processor design."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Memory Type | Description | Strengths | Weaknesses | Best Use Cases |\n",
    "|---|---|---|---|---|\n",
    "| DDR (Double Data Rate) | Standard memory used in most desktops and laptops. | Balanced performance and power consumption, widely supported. | Not as fast as other types, higher power consumption than LPDDR. | General computing, servers. |\n",
    "| LPDDR (Low Power DDR) | A version of DDR memory optimized for low power use. | Lower power consumption than DDR, good performance. | Not as fast as GDDR or HBM, less capacity than DDR. | Mobile devices, laptops. |\n",
    "| GDDR (Graphics DDR) | Memory designed for use in graphics cards. | Very high bandwidth, good for handling large amounts of data quickly. | Higher power consumption, more expensive. | Graphics cards, high-performance computing. |\n",
    "| HBM (High Bandwidth Memory) | High-performance memory stacked in multiple layers to achieve very high bandwidth. | Extremely high bandwidth, lower power consumption per bit than GDDR. | More expensive, requires advanced manufacturing techniques. | High-end graphics cards, supercomputers. |\n",
    "\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the fundamental limitation to scale memory depth:**\n",
    "\n",
    "First, let's consider the different ways memory depth (capacity) could be increased:\n",
    "\n",
    "- **Increasing the Density of Memory Cells**: This involves reducing the size of individual memory cells or increasing the number of cells per chip. However, this approach is limited by the physical constraints of semiconductor manufacturing. As we approach the limits of Moore's Law, it becomes increasingly difficult to continue shrinking memory cells.\n",
    "\n",
    "- **Stacking Memory Layers**: Technologies like 3D NAND and HBM (High Bandwidth Memory) increase memory depth by stacking layers of memory cells on top of each other. This can significantly increase capacity, but it also introduces challenges with heat dissipation and manufacturing complexity.\n",
    "\n",
    "- **Using Multi-Level Cells (MLC)**: MLC technology allows each memory cell to store more than one bit of information, effectively increasing capacity. However, MLC memory is somewhat limited and not yet practical for DRAM due to complexity and cell signal level limitations. \n",
    "\n",
    "- **Expanding the Memory Bus**: Increasing the width of the memory bus (the data path between the memory and the CPU) can allow for more data to be transferred at once, effectively increasing the capacity of the system. However, this can also increase power consumption and complexity.\n",
    "\n",
    "- **Multi-Rank Memory Systems**: In a multi-rank memory system, multiple 'ranks' of memory chips share the same memory bus. Each rank acts as a separate memory module, effectively increasing the total memory capacity. However, since only one rank can be accessed at a time, this can introduce latency when switching between ranks. Another concern is data integrity. Multi-rank systems in some configurations add additional loading the data channels which limits performance. \n",
    "\n",
    "Each of these approaches has its own trade-offs and limitations. Ultimately, the ability to scale memory depth is limited by a combination of physical, technological, and economic factors.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Level Challenges\n",
    "\n",
    "There are really only three ways to fundamentally scale a system. **Wider, Faster, and Increased Depth**.\n",
    "- Wider (more channels)\n",
    "- Faster (increased BW per channel and page size)\n",
    "- Increased depth (Increased address space for a given data channel)\n",
    "    - Increase on-die memory\n",
    "    - Virtually increase memory depth off-die\n",
    "        - Stacking DRAM die within a DRAM module/package\n",
    "        - Unbuffered DRAM muxing\n",
    "        - Buffered DRAM muxing\n",
    "\n",
    "\n",
    "**System tradeoffs:**\n",
    "- **Wider:** Adding channels to CPU for bandwidth and capacity (AKA wide and short-depth)\n",
    "    - Board form-factor and routing limitations\n",
    "    - SOC die area cost and reduced reliability (increased chance of failure)\n",
    "- **Faster:** Increasing data rates for bandwidth and capacity (AKA narrow and long-depth)\n",
    "    - Channel signal integrity limits and increasing IO design complexity\n",
    "    - Capacity can only be reached by loading the channel or buffering DRAMs. Buffering results in latency impacts.\n",
    "- **Increased Depth:** Adding more addressable space per channel\n",
    "    - DRAM die stacking is promissing but has stack capacity limits driven by reliability and is still expensive (TODO: verify cost)\n",
    "    - Unbuffered DIMMs provide low latency memory capacity muxing but at the cost of signal integrity leading to scale limitation\n",
    "    - Buffered DIMMs provide extensive scalability for capacity but at the cost of latency\n",
    "    - DRAM stacking can be combined with DIMMs. Ultimatly board routing congestion results in practical limits for scaling capacity. \n",
    "\n",
    "An LRDIMM (Load Reduced DIMM) is capable of dramatically improving the total DRAM capacity in a system with high-bandwidth as both the CA and Data paths are electrically isolated from DRAM loads as these signals are buffered. The tradeoff as mentioned earlier is latency, and also power efficiency. The buffered die if effectively a simplified PHY die which increases power as the buffered die must now link between the memory controller channel and the buffer-to-DRAM channels. An additional TX/RX pair are needed. The effectively reduces pj/bit efficiencies around 30%.\n",
    "\n",
    "<br>\n",
    "\n",
    "TODO: Insert code with parameters showing estimated system scaling capability with an LRDIMM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRDIMM code to estimate scaling\n",
    "\n",
    "channels = 2\n",
    "ranks = 4\n",
    "bits = 64\n",
    "memoryCapacityPC = 32 # GB per channel\n",
    "memoryCapacity = memoryCapacityPC * channels\n",
    "\n",
    "\n",
    "speed = 3200 # MT/s\n",
    "tCK = 1/speed\n",
    "tRCD = 13.75e-9\n",
    "tRP = 13.75e-9\n",
    "tCL = 13.75e-9\n",
    "tRAS = 33e-9\n",
    "tWR = 15e-9\n",
    "tWTR = 7.5e-9\n",
    "tRRD = 7.5e-9\n",
    "tFAW = 33e-9\n",
    "tRFC = 350e-9\n",
    "tREFI = 7.8e-6\n",
    "tXPDLL = 10e-9\n",
    "tXP = 2*tCK\n",
    "tXS = 5*tCK\n",
    "tXSDLL = 10e-9\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State-of-the-art Depth Scaling\n",
    "\n",
    "TODO: \n",
    "- Add example of large capacity sytems\n",
    "- Add motivation for systems to scale\n",
    "\n",
    "DRAM die stacking for capacity increase. Is this simply a new form of a DIMM?\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# DIMMs and Multi-Rank Systems\n",
    "\n",
    "**Multi-Rank Memory Systems:**\n",
    "\n",
    "In multi-rank memory systems, each rank shares the same data bus, and only one rank can be accessed at a time. When a rank is not being accessed, it is put into a high-impedance state to avoid interfering with the data bus. However, having multiple ranks connected to the same bus can still increase the electrical load on the bus, which can impact signal integrity and potentially limit the maximum speed of the memory.\n",
    "\n",
    "To mitigate this, some memory systems use a technology called \"registering\" or \"buffering\". Registered or buffered memory modules have a register between the DRAM modules and the memory controller. This register re-drives the signals from the memory controller to each rank, effectively isolating the memory controller from the load of the DRAM modules. This can improve signal integrity and allow for more ranks or higher-speed operation.\n",
    "\n",
    "However, the register also introduces a small delay in data transfer, which can slightly reduce performance. Therefore, registered memory is typically used in servers and other high-performance applications where stability and capacity are more important than the small performance hit. In contrast, unbuffered memory, which does not have this register, is typically used in consumer desktops and laptops where maximum performance is more important."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a DIMM?\n",
    "As shown in the diagram below, the main function of a DIMM is to extend the ability for a processor to send and retreive data from a large number of DRAM die. Thus effectively increasing the memory capacity of the system. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"img/dimm_ca.png\" alt=\"DDR Memory DIMMs\">\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| DIMM Type | Description | Max Capacity Capability | Min Latency Performance | Max Data Bandwidth Performance | Is Data Buffered? | Is Command Address Buffered? |\n",
    "|---|---|---|---|---|---|---|\n",
    "| UDIMM | Most common type of memory found in personal computers and workstations. | Low | High | High | No | No |\n",
    "| RDIMM | Contains a register that acts as a buffer between the memory controller and the memory chips. Used in servers and high-end workstations. | Medium | Medium | Medium | No | Yes |\n",
    "| LRDIMM | Includes a buffer that reduces the load on the memory controller even more than RDIMMs, allowing for even higher capacities. Used in high-end servers. | High | Low | Low | Yes | Yes |\n",
    "| FBDIMM | Includes an advanced memory buffer (AMB) that acts as a memory controller for the module. Largely obsolete. | High | Very Low | Low | Yes | Yes |\n",
    "| SO-DIMM | Smaller versions of DIMMs used in laptops and other small form factor devices. | Low | High | High | No | No |\n",
    "| ECC DIMM | Includes error-checking and correction capabilities. Can be unbuffered, registered, or load-reduced. | Varies | Varies | Varies | Varies | Varies |\n",
    "| NVDIMM | Uses non-volatile memory to provide persistent storage that retains data even when the system is powered off. | Medium to High | Low to Medium | Medium to High | Varies | Varies |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
